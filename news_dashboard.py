import streamlit as st
import feedparser
import ssl
import urllib.parse  # <--- [í•µì‹¬] ì´ê±° ì¶”ê°€í–ˆë‹¤ (í•œê¸€ ë³€í™˜ê¸°)
from datetime import datetime, timedelta
from dateutil import parser

# ---------------------------------------------------------
# 1. íšŒì‚¬ ë³´ì•ˆë§(SSL) ìš°íšŒ ì„¤ì •
# ---------------------------------------------------------
if hasattr(ssl, '_create_unverified_context'):
    ssl._create_default_https_context = ssl._create_unverified_context

# ---------------------------------------------------------
# 2. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="ì˜ì—…ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“°",
    layout="wide"
)

st.title("ğŸ“° B2B ì˜ì—… ì´ìŠˆ & ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§")
st.markdown("í˜„ëŒ€ë¦¬ë°”íŠ¸ ì˜ì—…ë§¨ì„ ìœ„í•œ **ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ê¸°**")

# ---------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” ì„¤ì •
# ---------------------------------------------------------
st.sidebar.header("ğŸ› ï¸ ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •")

# í‚¤ì›Œë“œ ì…ë ¥ì°½
default_keywords = "í˜¸í…” ë¦¬ëª¨ë¸ë§, ê±´ìì¬ ê°€ê²©, ê±´ì„¤ì—… ì „ë§, í˜„ëŒ€ë¦¬ë°”íŠ¸, í•œìƒ˜ B2B, ì‹ ê·œ ë¦¬ì¡°íŠ¸"
user_input = st.sidebar.text_area(
    "ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì½¤ë§ˆ , ë¡œ êµ¬ë¶„)", 
    value=default_keywords,
    height=100
)

# ì½¤ë§ˆë¡œ ì˜ë¼ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
keywords = [k.strip() for k in user_input.split(',') if k.strip()]

# ê¸°ê°„ í•„í„°ë§
period_option = st.sidebar.selectbox(
    "ì¡°íšŒ ê¸°ê°„",
    ["ì „ì²´ ë³´ê¸°", "ìµœê·¼ 24ì‹œê°„", "ìµœê·¼ 3ì¼", "ìµœê·¼ 1ì£¼ì¼"]
)

st.sidebar.info(f"í˜„ì¬ **{len(keywords)}ê°œ** í‚¤ì›Œë“œë¥¼ ê°ì‹œ ì¤‘ì´ë°ì´!")

# ---------------------------------------------------------
# 4. ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (ì—¬ê¸°ê°€ ë¬¸ì œì˜€ìŒ -> ìˆ˜ì •ì™„ë£Œ!)
# ---------------------------------------------------------
@st.cache_data(ttl=600)
def get_news(search_terms):
    all_news = []
    
    for term in search_terms:
        # [ìˆ˜ì •] í•œê¸€ í‚¤ì›Œë“œë¥¼ URL ì „ìš© ë¬¸ìë¡œ ë³€í™˜ (ì¸ì½”ë”©)
        encoded_term = urllib.parse.quote(term)
        
        # ë³€í™˜ëœ í‚¤ì›Œë“œë¡œ URL ìƒì„±
        url = f"https://news.google.com/rss/search?q={encoded_term}&hl=ko&gl=KR&ceid=KR:ko"
        
        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        feed = feedparser.parse(url)
        
        for entry in feed.entries:
            try:
                pub_date = parser.parse(entry.published)
            except:
                pub_date = datetime.now()

            all_news.append({
                'keyword': term,
                'title': entry.title,
                'link': entry.link,
                'published': pub_date,
                'source': entry.get('source', {}).get('title', 'Google News')
            })
            
    return all_news

# ---------------------------------------------------------
# 5. ë©”ì¸ ë¡œì§ ì‹¤í–‰
# ---------------------------------------------------------
if st.button("ğŸ”„ ìµœì‹  ë‰´ìŠ¤ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°"):
    st.cache_data.clear()

with st.spinner('ë‰´ìŠ¤ ê¸ì–´ì˜¤ëŠ” ì¤‘... ì ë§Œ ê¸°ë‹¤ë¦¬ë°”ë¼...'):
    news_list = get_news(keywords)

# ë‚ ì§œìˆœ ì •ë ¬
news_list.sort(key=lambda x: x['published'], reverse=True)

# ê¸°ê°„ í•„í„°ë§ ì ìš©
filtered_news = []
if news_list:
    now = datetime.now(news_list[0]['published'].tzinfo) 

    for news in news_list:
        pub_date = news['published']
        
        if period_option == "ìµœê·¼ 24ì‹œê°„":
            if (now - pub_date) > timedelta(hours=24): continue
        elif period_option == "ìµœê·¼ 3ì¼":
            if (now - pub_date) > timedelta(days=3): continue
        elif period_option == "ìµœê·¼ 1ì£¼ì¼":
            if (now - pub_date) > timedelta(days=7): continue
            
        filtered_news.append(news)

# ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
if not filtered_news:
    st.warning("ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤! í‚¤ì›Œë“œë¥¼ ë°”ê¾¸ê±°ë‚˜ ê¸°ê°„ì„ ëŠ˜ë ¤ë³´ë˜ì´.")
else:
    st.success(f"ì´ **{len(filtered_news)}ê°œ**ì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ë‹¤!")
    
    for i, news in enumerate(filtered_news):
        date_str = news['published'].strftime("%Y-%m-%d %H:%M")
        
        with st.expander(f"[{news['keyword']}] {news['title']}"):
            st.write(f"**ì¶œì²˜:** {news['source']} | **ì¼ì‹œ:** {date_str}")
            st.link_button("ê¸°ì‚¬ ì›ë¬¸ ë³´ëŸ¬ê°€ê¸° ğŸ‘‰", news['link'])
