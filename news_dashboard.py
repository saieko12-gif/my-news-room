import ssl
import time
import feedparser
from datetime import datetime, timedelta
from urllib.parse import quote

import streamlit as st

# íšŒì‚¬ SSL ì¸ì¦ì„œ ë¬¸ì œ ìš°íšŒ (í•„ìˆ˜ ì„¤ì •)
ssl._create_default_https_context = ssl._create_unverified_context

# -----------------------------
# ì„¤ì •: í‚¤ì›Œë“œ ëª©ë¡
# -----------------------------
CORE_SALES_KEYWORDS = [
    "í˜¸í…” ë¦¬ëª¨ë¸ë§",
    "ê±´ìì¬ ê°€ê²©",
    "ê±´ì„¤ì—… ì „ë§",
]

ORDER_OPPORTUNITY_KEYWORDS = [
    "ì‹ ê·œ ë¦¬ì¡°íŠ¸ ë¶„ì–‘",
    "ì¬ê±´ì¶• ì¸í…Œë¦¬ì–´",
    "ì˜¤í”¼ìŠ¤ ë¦¬ëª¨ë¸ë§",
]

INDUSTRY_TREND_KEYWORDS = [
    "í•œìƒ˜ B2B",
    "LXí•˜ìš°ì‹œìŠ¤",
    "í˜„ëŒ€ë¦¬ë°”íŠ¸",
]

ALL_KEYWORDS = (
    CORE_SALES_KEYWORDS
    + ORDER_OPPORTUNITY_KEYWORDS
    + INDUSTRY_TREND_KEYWORDS
)


# -----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# -----------------------------
def build_google_news_rss_url(keyword: str) -> str:
    base = "https://news.google.com/rss/search"
    query = quote(keyword)
    # í•œêµ­ì–´/í•œêµ­ ê¸°ì¤€
    return f"{base}?q={query}&hl=ko&gl=KR&ceid=KR:ko"


def get_published_datetime(entry):
    """RSS ì—”íŠ¸ë¦¬ì—ì„œ datetime ê°ì²´ ì¶”ì¶œ."""
    # feedparserê°€ ì œê³µí•˜ëŠ” ì‹œê°„ ì •ë³´ í™œìš©
    if hasattr(entry, "published_parsed") and entry.published_parsed:
        return datetime(*entry.published_parsed[:6])

    # published ë¬¸ìì—´ì´ ìˆì„ ê²½ìš°, dateutilì´ ìˆìœ¼ë©´ í™œìš©
    if hasattr(entry, "published"):
        published_str = getattr(entry, "published", None)
        if published_str:
            try:
                from dateutil import parser as dateutil_parser  # type: ignore

                return dateutil_parser.parse(published_str)
            except Exception:
                # dateutil ë¯¸ì„¤ì¹˜ ë˜ëŠ” íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
                pass

    return None


def format_datetime_kr(dt: datetime | None) -> str:
    """í•œêµ­í˜• í‘œì‹œ: 2024-02-05 (ì›”) 14:30"""
    if dt is None:
        return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

    weekdays = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
    weekday_kr = weekdays[dt.weekday()]
    return dt.strftime(f"%Y-%m-%d ({weekday_kr}) %H:%M")


def extract_source(entry) -> str:
    # 1) entry.source.title í˜•íƒœ
    try:
        source = getattr(getattr(entry, "source", None), "title", None)
        if source:
            return source
    except Exception:
        pass

    # 2) dict í˜•íƒœ
    src = getattr(entry, "source", None)
    if isinstance(src, dict):
        if "title" in src:
            return src["title"]

    # 3) ì œëª©ì—ì„œ "- ì–¸ë¡ ì‚¬ëª…" íŒ¨í„´ ì¶”ì¶œ
    title = getattr(entry, "title", "")
    if " - " in title:
        return title.split(" - ")[-1].strip()

    return "ì¶œì²˜ ë¯¸ìƒ"


# -----------------------------
# ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ)
# -----------------------------
@st.cache_data(show_spinner="ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def fetch_news_for_keyword(keyword: str, refresh_token: float):
    """í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (refresh_tokenìœ¼ë¡œ ê°•ì œ ê°±ì‹ )."""
    url = build_google_news_rss_url(keyword)
    feed = feedparser.parse(url)

    news_list = []
    for entry in feed.entries:
        dt = get_published_datetime(entry)
        news_list.append(
            {
                "title": getattr(entry, "title", "ì œëª© ì—†ìŒ"),
                "link": getattr(entry, "link", "#"),
                "published_dt": dt,
                "published_display": format_datetime_kr(dt),
                "source": extract_source(entry),
                "summary": getattr(entry, "summary", ""),
            }
        )
    return news_list


@st.cache_data(show_spinner=False)
def fetch_all_news(keywords, refresh_token: float):
    """ì—¬ëŸ¬ í‚¤ì›Œë“œì— ëŒ€í•´ í•œ ë²ˆì— ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°."""
    result = {}
    for kw in keywords:
        result[kw] = fetch_news_for_keyword(kw, refresh_token)
    return result


def filter_news_by_period(items, period_label: str):
    """ì¡°íšŒ ê¸°ê°„ ë¼ë²¨ì— ë”°ë¼ ë‰´ìŠ¤ ëª©ë¡ í•„í„°ë§."""
    if period_label == "ì „ì²´ ë³´ê¸°":
        return items

    now = datetime.now()

    if period_label == "ìµœê·¼ 24ì‹œê°„":
        threshold = now - timedelta(days=1)
    elif period_label == "ìµœê·¼ 1ì£¼ì¼":
        threshold = now - timedelta(days=7)
    elif period_label == "ìµœê·¼ 1ê°œì›”":
        threshold = now - timedelta(days=30)
    else:
        return items

    return [
        item
        for item in items
        if item.get("published_dt") is not None
        and item["published_dt"] >= threshold
    ]


# -----------------------------
# Streamlit UI
# -----------------------------
def main():
    st.set_page_config(
        page_title="B2B ì˜ì—…ìš© ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ê¸°",
        layout="wide",
    )

    st.title("ğŸ“Š B2B ì˜ì—…ìš© ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ê¸°")
    st.caption("êµ¬ê¸€ ë‰´ìŠ¤ RSS + Streamlit ëŒ€ì‹œë³´ë“œ")

    # ì„¸ì…˜ ìƒíƒœ: ë§ˆì§€ë§‰ ê°±ì‹  ì‹œê°„ (ìºì‹œ ë¬´íš¨í™”ë¥¼ ìœ„í•œ í† í°)
    if "last_refresh" not in st.session_state:
        st.session_state.last_refresh = time.time()

    # -------------------------
    # ì‚¬ì´ë“œë°” ì˜ì—­
    # -------------------------
    with st.sidebar:
        st.header("ğŸ” í‚¤ì›Œë“œ í•„í„°")

        period_label = st.selectbox(
            "ì¡°íšŒ ê¸°ê°„",
            ["ì „ì²´ ë³´ê¸°", "ìµœê·¼ 24ì‹œê°„", "ìµœê·¼ 1ì£¼ì¼", "ìµœê·¼ 1ê°œì›”"],
            index=0,
        )

        keyword_filter_mode = st.radio(
            "ì¡°íšŒ ë°©ì‹ ì„ íƒ",
            ["ì „ì²´ ë³´ê¸°", "ë‹¨ì¼ í‚¤ì›Œë“œ ì„ íƒ"],
            index=0,
        )

        selected_keyword = None
        if keyword_filter_mode == "ë‹¨ì¼ í‚¤ì›Œë“œ ì„ íƒ":
            selected_keyword = st.selectbox(
                "í‚¤ì›Œë“œ ì„ íƒ",
                ALL_KEYWORDS,
                index=0,
                help="ê´€ì‹¬ ìˆëŠ” í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
            )

        st.markdown("---")

        if st.button("ğŸ”„ ë°ì´í„° ê°±ì‹ ", use_container_width=True):
            # ìºì‹œ ë¬´íš¨í™”ë¥¼ ìœ„í•´ í† í° ë³€ê²½
            st.session_state.last_refresh = time.time()
            st.success("ìµœì‹  ë‰´ìŠ¤ë¡œ ê°±ì‹ í–ˆìŠµë‹ˆë‹¤.")

        st.markdown("#### í‚¤ì›Œë“œ ê·¸ë£¹")
        st.markdown("**í•µì‹¬ ì˜ì—…**")
        for k in CORE_SALES_KEYWORDS:
            st.write(f"- {k}")

        st.markdown("**ìˆ˜ì£¼ ê¸°íšŒ**")
        for k in ORDER_OPPORTUNITY_KEYWORDS:
            st.write(f"- {k}")

        st.markdown("**ì—…ê³„ ë™í–¥**")
        for k in INDUSTRY_TREND_KEYWORDS:
            st.write(f"- {k}")

    # -------------------------
    # ë©”ì¸ ì½˜í…ì¸ : ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
    # -------------------------
    st.subheader("ğŸ“° ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸")

    # ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    refresh_token = st.session_state.last_refresh

    if keyword_filter_mode == "ì „ì²´ ë³´ê¸°":
        raw_news_data = fetch_all_news(ALL_KEYWORDS, refresh_token)
    else:
        # ë‹¨ì¼ í‚¤ì›Œë“œë§Œ ì¡°íšŒ
        news_list = fetch_news_for_keyword(selected_keyword, refresh_token)
        raw_news_data = {selected_keyword: news_list}

    # ê¸°ê°„ í•„í„° ë° ë‚ ì§œìˆœ ì •ë ¬ ì ìš©
    news_data = {}
    for keyword, items in raw_news_data.items():
        filtered_items = filter_news_by_period(items, period_label)
        # ìµœì‹  ë‰´ìŠ¤ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬
        filtered_items.sort(
            key=lambda x: x.get("published_dt") or datetime.min,
            reverse=True,
        )
        news_data[keyword] = filtered_items

    # -------------------------
    # ë‰´ìŠ¤ ì¶œë ¥ (ì¹´ë“œ / expander í˜•íƒœ)
    # -------------------------
    total_count = sum(len(v) for v in news_data.values())
    st.write(f"ì´ **{total_count}ê±´**ì˜ ë‰´ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤.")

    if total_count == 0:
        st.info("í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for keyword, items in news_data.items():
        if not items:
            continue

        st.markdown(f"### ğŸ”¸ í‚¤ì›Œë“œ: **{keyword}**")

        for idx, item in enumerate(items, start=1):
            with st.expander(f"{idx}. {item['title']}"):
                col1, col2 = st.columns([3, 1])

                with col1:
                    st.write(f"**ê²Œì‹œì¼**: {item['published_display']}")
                    st.write(f"**ì¶œì²˜**: {item['source']}")
                    if item["summary"]:
                        st.write("---")
                        st.write(item["summary"], unsafe_allow_html=True)

                with col2:
                    st.link_button(
                        "ì›ë¬¸ ë³´ê¸°",
                        item["link"],
                        use_container_width=True,
                    )

        st.markdown("---")


if __name__ == "__main__":
    main()