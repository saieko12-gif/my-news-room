import streamlit as st
import feedparser
import ssl
import urllib.parse
from datetime import datetime, timedelta
from dateutil import parser

# ---------------------------------------------------------
# 1. íšŒì‚¬ ë³´ì•ˆë§(SSL) ìš°íšŒ ì„¤ì •
# ---------------------------------------------------------
if hasattr(ssl, '_create_unverified_context'):
    ssl._create_default_https_context = ssl._create_unverified_context

# ---------------------------------------------------------
# 2. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="ì˜ì—…ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“°",
    layout="wide"
)

st.title("ğŸ“° B2B ì˜ì—… ì´ìŠˆ & ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§")
st.markdown("ë²„íŠ¼ í•˜ë‚˜ë¡œ í‚¤ì›Œë“œ ìë™ ì„¸íŒ…! **ìŠ¤ë§ˆíŠ¸í•œ ì˜ì—…ë§¨ì˜ ë¹„ë°€ë¬´ê¸°**")

# ---------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” ì„¤ì • (ì—¬ê¸°ê°€ í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ!)
# ---------------------------------------------------------
st.sidebar.header("ğŸ› ï¸ ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •")

# --- [ê¸°ëŠ¥ ì¶”ê°€] í‚¤ì›Œë“œ í”„ë¦¬ì…‹(Preset) ì •ì˜ ---
# ë‹ˆê°€ ì›í•˜ë˜ 'í‚¤ì›Œë“œ ë¬¶ìŒ'ë“¤ì´ë‹¤. ì…ë§›ëŒ€ë¡œ ìˆ˜ì •í•´ë„ ëœë‹¤.
preset_hotel = "í˜¸í…” ë¦¬ëª¨ë¸ë§, ì‹ ê·œ í˜¸í…” ì˜¤í”ˆ, ë¦¬ì¡°íŠ¸ ì°©ê³µ, 5ì„±ê¸‰ í˜¸í…” ë¦¬ë‰´ì–¼, í˜¸í…” FF&E, ìƒí™œìˆ™ë°•ì‹œì„¤ ë¶„ì–‘, í˜¸í…” ë§¤ê°"
preset_office = "ì‚¬ì˜¥ ì´ì „, í†µí•© ì‚¬ì˜¥ ê±´ë¦½, ìŠ¤ë§ˆíŠ¸ ì˜¤í”¼ìŠ¤, ê¸°ì—… ì—°ìˆ˜ì› ê±´ë¦½, ê³µê³µì²­ì‚¬ ë¦¬ëª¨ë¸ë§, ê³µìœ  ì˜¤í”¼ìŠ¤ ì¶œì , ì˜¤í”¼ìŠ¤ ì¸í…Œë¦¬ì–´"
preset_market = "ê±´ìì¬ ê°€ê²©, ì¹œí™˜ê²½ ìì¬, ëª¨ë“ˆëŸ¬ ì£¼íƒ, ì•„íŒŒíŠ¸ íŠ¹íŒ ê°€êµ¬, í•œìƒ˜ B2B, LXí•˜ìš°ì‹œìŠ¤, í˜„ëŒ€ê±´ì„¤ ìˆ˜ì£¼, GSê±´ì„¤ ìˆ˜ì£¼"
preset_all = f"{preset_hotel}, {preset_office}, {preset_market}" # ë‹¤ í•©ì¹œê±°

# --- [ê¸°ëŠ¥ ì¶”ê°€] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
# ì…ë ¥ì°½ì— ë“¤ì–´ê°ˆ ê°’ì„ ê¸°ì–µí•˜ëŠ” ë³€ìˆ˜(storage)ë¥¼ ë§Œë“ ë‹¤.
if 'search_keywords' not in st.session_state:
    st.session_state['search_keywords'] = preset_hotel # ê¸°ë³¸ê°’ì€ í˜¸í…”ë¡œ ì‹œì‘

# --- [ê¸°ëŠ¥ ì¶”ê°€] ë°”ë¡œê°€ê¸° ë²„íŠ¼ë“¤ ---
st.sidebar.subheader("âš¡ í‚¤ì›Œë“œ ìë™ ì™„ì„± (í´ë¦­í•´ë´ë¼)")

# ë²„íŠ¼ì„ 2ì—´ë¡œ ì˜ˆì˜ê²Œ ë°°ì¹˜
col1, col2 = st.sidebar.columns(2)

# ê° ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ -> ì €ì¥ëœ ë³€ìˆ˜(search_keywords) ê°’ì„ ë°”ê¾¼ë‹¤!
with col1:
    if st.button("ğŸ¨ í˜¸í…”/ë¦¬ì¡°íŠ¸"):
        st.session_state['search_keywords'] = preset_hotel
    if st.button("ğŸ—ï¸ ê±´ìì¬/ë™í–¥"):
        st.session_state['search_keywords'] = preset_market
        
with col2:
    if st.button("ğŸ¢ ì˜¤í”¼ìŠ¤/ì‚¬ì˜¥"):
        st.session_state['search_keywords'] = preset_office
    if st.button("ğŸ”¥ ì˜ì—… í’€ì„¸íŠ¸"):
        st.session_state['search_keywords'] = preset_all

# --- ì…ë ¥ì°½ (ì—¬ê¸°ì„œ key='search_keywords'ê°€ í•µì‹¬!) ---
# ìœ„ì—ì„œ ë²„íŠ¼ ëˆ„ë¥´ë©´ ë°”ë€ ê°’ì´ ì—¬ê¸°ì— ìë™ìœ¼ë¡œ ì™ ë“¤ì–´ê°„ë‹¤.
user_input = st.sidebar.text_area(
    "ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥)", 
    key='search_keywords', # ë²„íŠ¼ì´ë‘ ì—°ê²°ëœ ê³ ë¦¬
    height=150
)

# ì½¤ë§ˆë¡œ ì˜ë¼ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
keywords = [k.strip() for k in user_input.split(',') if k.strip()]

# ê¸°ê°„ í•„í„°ë§
period_option = st.sidebar.selectbox(
    "ì¡°íšŒ ê¸°ê°„",
    ["ì „ì²´ ë³´ê¸°", "ìµœê·¼ 24ì‹œê°„", "ìµœê·¼ 3ì¼", "ìµœê·¼ 1ì£¼ì¼"]
)

st.sidebar.info(f"í˜„ì¬ **{len(keywords)}ê°œ** í‚¤ì›Œë“œë¥¼ ê°ì‹œ ì¤‘ì´ë°ì´!")

# ---------------------------------------------------------
# 4. ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ---------------------------------------------------------
@st.cache_data(ttl=600)
def get_news(search_terms):
    all_news = []
    
    for term in search_terms:
        encoded_term = urllib.parse.quote(term)
        url = f"https://news.google.com/rss/search?q={encoded_term}&hl=ko&gl=KR&ceid=KR:ko"
        
        feed = feedparser.parse(url)
        
        for entry in feed.entries:
            try:
                pub_date = parser.parse(entry.published)
            except:
                pub_date = datetime.now()

            all_news.append({
                'keyword': term,
                'title': entry.title,
                'link': entry.link,
                'published': pub_date,
                'source': entry.get('source', {}).get('title', 'Google News')
            })
            
    return all_news

# ---------------------------------------------------------
# 5. ë©”ì¸ ë¡œì§ ì‹¤í–‰
# ---------------------------------------------------------
if st.button("ğŸ”„ ìµœì‹  ë‰´ìŠ¤ ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°"):
    st.cache_data.clear()

with st.spinner('ë‰´ìŠ¤ ê¸ì–´ì˜¤ëŠ” ì¤‘... ì ë§Œ ê¸°ë‹¤ë¦¬ë°”ë¼...'):
    news_list = get_news(keywords)

# ë‚ ì§œìˆœ ì •ë ¬
news_list.sort(key=lambda x: x['published'], reverse=True)

# ê¸°ê°„ í•„í„°ë§ ì ìš©
filtered_news = []
if news_list:
    now = datetime.now(news_list[0]['published'].tzinfo) 

    for news in news_list:
        pub_date = news['published']
        
        if period_option == "ìµœê·¼ 24ì‹œê°„":
            if (now - pub_date) > timedelta(hours=24): continue
        elif period_option == "ìµœê·¼ 3ì¼":
            if (now - pub_date) > timedelta(days=3): continue
        elif period_option == "ìµœê·¼ 1ì£¼ì¼":
            if (now - pub_date) > timedelta(days=7): continue
            
        filtered_news.append(news)

# ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
if not filtered_news:
    st.warning("ì¡°ê±´ì— ë§ëŠ” ë‰´ìŠ¤ê°€ ì—†ë‹¤! í‚¤ì›Œë“œë¥¼ ë°”ê¾¸ê±°ë‚˜ ê¸°ê°„ì„ ëŠ˜ë ¤ë³´ë˜ì´.")
else:
    st.success(f"ì´ **{len(filtered_news)}ê°œ**ì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ë‹¤!")
    
    for i, news in enumerate(filtered_news):
        date_str = news['published'].strftime("%Y-%m-%d %H:%M")
        
        with st.expander(f"[{news['keyword']}] {news['title']}"):
            st.write(f"**ì¶œì²˜:** {news['source']} | **ì¼ì‹œ:** {date_str}")
            st.link_button("ê¸°ì‚¬ ì›ë¬¸ ë³´ëŸ¬ê°€ê¸° ğŸ‘‰", news['link'])
